- Experience:
    - Describe your work relevant to scientific software (1000 - 1500 characters).
        -  A significant objective of my team within the ECP (ExaSGD) was to port a large CPU-bound library for solving nonlinear problems (HiOp) to take full advantage of next generation GPU-capable HPC clusters (more or less specifics about each project?). A significant blocker to this goal is the variety of hardware and software capabilities available on various target clusters: our software must take advantage of a variety of GPU devices (AMD and NVIDIA), CPU architectures (Power9, ARM, and Intel), and software abstractions (OpenMP, Intel TBB).
        -  It was not a reasonable objective to write specific implementations for every single combination of hardware/software platforms, so we settled on a threefold strategy for developing the capability of this library:
        -  Develop a test suite for key linear algebra kernels independent of implementation
        -  Configure CI pipelines on clusters with various hardware and software capabilities
        -  Incrementally port each linear algebra kernel to use RAJA and Umpire portability layers to take advantage of hardware/software capabilities on each platform, subject to the same test suite as the original kernels
        -  RAJA is a compile-time portability layer that enabled our team to reimplement each linear algebra kernel only once, enabling the kernel to run on all target hardware and software platforms. Umpire is a runtime abstraction for memory management that allowed our team to allocate, copy, and move memory between various memory spaces, also independent of the platform. By writing our kernels using these two portability layers and supported by our test suite, we ensured that each kernel was functional on next generation hardware and software and sufficiently replaced the functionality of the original kernel. As of September 2020, we completed our key objective of solving HiOp's most representative NLP example using our portable linear algebra library.
    - Describe your background and experience relevant to being a BSSw Fellow (1000 - 1500 characters).
        -  My experience in the ECP has been focused on advocating sustainable software development practices and processes within ExaSGD. This has resulted in increased sustainability and collaboration on our two key scientific codebases (ExaGO and HiOp), which are now supported by rigorous testing frameworks. 
        -  Since developing HiOp and ExaGO's rigorous test suites, we have caught countless bugs which would have gone completely unnoticed without them. For example, developing and debugging the NLP example driver required significant trust in the linear algebra library, as the NLP formulation required significant debugging itself. This NLP driver operated as an integration test to ensure that all pieces of HiOp's linear algebra library were working as expected, and it is extremely unlikely we would have been able to debug the driver according to our deadlines without the software development best practices we put in place. This experience has made me a firm believer in the practices and processes I developed and enforced.
        -  In addition, I led several hackathons for ExaGO and HiOp in which colleagues from 5 national laboratories collaborated to implement portable and GPU-capable linear algebra kernels. These hackathons fostered a culture of collaboration and sustainable software development, and encouraged our colleagues at other national laboratories to pursue software best practices as well.
- Proposed work and impact:
    - What would you do as a BSSw Fellow? (1000 - 1500 characters).
        -  As a BSSw Fellow, I would like to create a set of metrics for quantifying software sustainability and technical capital. Technical debt is an extremely pressing issue in sustainable software development, and all large-scale scientific software teams must balance taking on technical debt and paying it off. A significant challenge in addressing these challenges is quantifying software quality. There are currently no standard metrics which combine test coverage, platform support, code readability, adherence to formatting standards, development processes, performance, and all other areas which determine the overall quality and sustainability of a given software collection. Purely qualitative analysis of the software capital of a codebase makes addressing technical debt and software sustainability very subjective and difficult. I would use the funding from the BSSw Fellowship to design such a standard.
        -  The standard would not require that a project use any given software stack in particular, but would be implementable within any stack. This way, any project would be able to measure their codebase against the metric, and the large-scale code quality of an entire collection of software projects may be measured. For example, the average code quality of all the repositories that make up ExaSGD may be measured against other ECP projects to measure the relative performance of the team. I would like to qualitatively measure the technical capital of HiOp as an action step after establishing the metrics.
        -  In practice, this may be a build script which builds and tests on all target platforms, using automated tools where appropriate (unit tests, integration tests, formatting, code coverage, etc), and developers on the team may fill out a short survey indicating how closely the project adheres to development process guidelines and other metrics that are not as easily automated.
    - What impact do you foresee from your efforts? (1000 - 1500 characters).
        -  I believe technical capital is a very valuable objective, but without a meaningful metric I have found that taking on technical debt to achieve short-term goals is often preferred. While this is sometimes a worthwhile tradeoff, we in the scientific software community must have a standardized measurement of technical capital in order to weigh it against short-term benefits. This metric would likely have 3 primary impacts:
        -  (a) Developers of scientific software would be highly incentivized to diligently adhere to their respective best practices. This would increase the sustainability of scientific software and give developers a clearer idea of how small actions and contributions affect the long-term sustainability and quality of a codebase.
        -  (b) Developers which do rigorously pursue sustainable software will be recognized by the sustainability metrics. Adherence to processes and documentation will be appropriately recognized as integral components of the scientific software development lifecycle. This recognition will further encourage best practices.
        -  (c) Developer productivity will eventually increase as the scientific software community reaps the benefits of this investment in sustainable software. When development teams invest in their software appropriately, code reuse becomes significantly more prevalent. This prevents development teams from recreating software already (poorly) developed by other groups. 
        -  I view adoption of this metric as an investment in long-term software sustainability from which the scientific software community may reap the benefits for many years to come.
    - Which BSSw focus areas and subtopics apply to your proposed work? Specify all that apply.
        -  See https://bssw.io for a list of focus areas and subtopics (e.g., Focus Area: Planning; Subtopic: Requirements).
        -  Focus Area: Planning, Collaboration; Subtopic: Software Process Improvement, Software Interoperability, Strategies for More Effective Teams, Projects and Organizations.
