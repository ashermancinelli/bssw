- Experience:
    - Describe your work relevant to scientific software (1000 - 1500 characters).
        -  A significant objective of my team within the Exascale Computing Project (ECP) was to port HiOp, a large CPU-bound library for solving nonlinear problems, to take full advantage of next generation GPU-capable high-performance computing (HPC) clusters. A significant blocker to this goal is the variety of hardware and software capabilities available on various target clusters: our software must take advantage of a variety of GPU devices (AMD and NVIDIA), CPU architectures (Power9, ARM, and Intel), and software abstractions (OpenMP, Intel TBB).
        -  It was not a reasonable objective to write specific implementations for every single combination of hardware/software platforms, so we settled on a threefold strategy for developing the capability of this library:
        -  Develop a test suite for key linear algebra kernels independent of implementation
        -  Configure continuous integration (CI) pipelines on clusters with various hardware and software capabilities
        -  Incrementally port each linear algebra kernel to use RAJA and Umpire portability layers to take advantage of hardware/software capabilities on each platform, subject to the same test suite as the original kernels
        -  RAJA is a compile-time portability layer that enabled our team to reimplement each linear algebra kernel only once, enabling the kernel to run on all target hardware and software platforms. Umpire is a runtime abstraction for memory management that allowed our team to allocate, copy, and move memory between various memory spaces, also independent of the platform. By writing our kernels using these two portability layers and supported by our test suite, we ensured that each kernel was functional on next generation hardware and software and sufficiently replaced the functionality of the original kernels. This strategy maximized the ratio of resulting technical capital per unit of effort invested. As of September 2020, we completed our key objective of solving HiOp's most representative example nonlinear problem using our portable linear algebra library.
    - Describe your background and experience relevant to being a BSSw Fellow (1000 - 1500 characters).
        -  My experience in the ECP has been focused on maximizing technical capital through sustainable software development practices and processes within a project with the goal of optimizing stochastic grid dynamics at exascale (ExaSGD). This has resulted in increased sustainability and collaboration on our two key scientific codebases (ExaGO and HiOp), which are now supported by rigorous testing frameworks.
        -  Since developing HiOp and ExaGO's rigorous test suites, we have caught countless bugs which would have gone completely unnoticed otherwise. For example, developing and debugging the HiOp's example problem required significant trust in the linear algebra library, as the problem formulation required significant debugging itself. This example use case operated as an integration test to ensure that all pieces of HiOp's linear algebra library were working as expected, and it is extremely unlikely we would have been able to debug the driver according to our deadlines without the software development best practices we put in place. This experience has made me a firm believer in the practices and processes I developed and enforced.
        -  In addition, I led several hackathons for ExaSGD projects in which colleagues from 5 national laboratories collaborated to implement portable and GPU-capable linear algebra kernels. These hackathons fostered a culture of collaboration and sustainable software development, and encouraged our colleagues at other national laboratories to pursue software best practices as well.
- Proposed work and impact:
    - What would you do as a BSSw Fellow? (1000 - 1500 characters).
        -  As a BSSw Fellow, I would like to create a set of metrics for quantifying software sustainability and technical capital. Technical debt is an extremely pressing issue in sustainable software development, and all large-scale scientific software teams must balance taking on technical debt and paying it off. There are currently no standard metrics which combine test coverage, platform support, readability, adherence to formatting standards, development processes, performance, and other areas which determine the overall quality and sustainability of a given software collection. Quantifying software quality is a prerequisite for effectively addressing technical debt, yet there are no reliable metrics; this is where I would spend my effort as a BSSw fellow. 
        - Other recognized efforts in this domain (see Barkmann et al) are often restricted to a specific software stack and programming paradigm. I do not beleive these strategies are sufficient for evaluating technical captial in large teams using many technologies. I would argue that they are therefore unfit for use in the ECP and the broader scientific community.
        -  The standard would not require that a project use any given software stack in particular, but would be implementable within any stack. This way, any project would be able to measure their codebase against the metric, and the large-scale code quality of an entire collection of software projects may be measured. For example, the average code quality of all the repositories that make up ExaSGD may be measured against other ECP projects to measure the relative performance of the team. I would like to quantitatively measure the technical capital of HiOp as an action step after establishing the metrics.
        -  In practice, this may be a build script which builds and tests on all target platforms, using automated tools where appropriate (unit tests, integration tests, formatting, code coverage, etc), and developers on the team may fill out a short survey indicating how closely the project adheres to development process guidelines and other metrics that are not as easily automated. Results would be binned into categories and labeled.
    - What impact do you foresee from your efforts? (1000 - 1500 characters).
        -  I believe technical capital is a very valuable objective, but without a meaningful metric I have found that taking on technical debt to achieve short-term goals is often preferred. While this is sometimes a worthwhile tradeoff, we in the scientific software community must have a standardized measurement of technical capital in order to weigh it against short-term benefits. This metric would likely have 3 primary impacts:
        -  (a) Developers of scientific software would be highly incentivized to diligently adhere to their respective best practices. This would increase the sustainability of scientific software and give developers a clearer idea of how small actions and contributions affect the long-term sustainability and quality of a codebase.
        -  (b) Developers which do rigorously pursue sustainable software will be recognized by the sustainability metrics. Adherence to processes and documentation will be appropriately recognized as integral components of the scientific software development lifecycle. This recognition will further encourage best practices.
        -  (c) Developer productivity will eventually increase as the scientific software community reaps the benefits of this investment in sustainable software. When development teams invest in their software appropriately, code reuse becomes significantly more prevalent. This prevents development teams from recreating software already (poorly) developed by other groups. 
        -  I view adoption of this metric as an investment in long-term software sustainability from which the scientific software community may reap the benefits for many years to come.
    - Which BSSw focus areas and subtopics apply to your proposed work? Specify all that apply.
        -  See https://bssw.io for a list of focus areas and subtopics (e.g., Focus Area: Planning; Subtopic: Requirements).
        -  Focus Area: Planning, Collaboration; Subtopic: Software Process Improvement, Software Interoperability, Strategies for More Effective Teams, Projects and Organizations.


References (not intended for the application but for personal use):

- [Quantitative Evaluation of Software Quality Metrics in Open-Source Projects](https://ieeexplore.ieee.org/abstract/document/5136793)
- [Software Quality Metrics for Object-Oriented Environments](http://people.ucalgary.ca/~far/Lectures/SENG421/PDF/oocross.pdf)
- [Why quality?: ISO 9126 software quality metrics (Functionality) support by UML suite](https://dl.acm.org/doi/abs/10.1145/1050849.1050860)
